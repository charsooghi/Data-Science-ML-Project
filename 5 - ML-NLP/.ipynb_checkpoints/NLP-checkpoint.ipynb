{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Natural Language Processing (NLP)\n",
    "\n",
    "### Import Data\n",
    "First of all we need some data to work with. For this propose we can use the [public SMS Spam Collection Data Set](https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection) on machine learning repository of UCI.\n",
    "\n",
    "After downloding and unzipping the data, there would be two files:\n",
    "- readme file including the information about the data Set\n",
    "- SMSSpamCollection file which contains the data\n",
    "\n",
    "In summary, the data contains more than 5000 messages that have been collected for SMS Spam research (4,827 SMS legitimate messages (86.6%) and a total of 747 (13.4%) spam messages).\n",
    "\n",
    "The files contain one message per line. Each line is composed by two columns: one with label (ham or spam) and other with the raw text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ham\tGo until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\n",
      "1 ham\tOk lar... Joking wif u oni...\n",
      "2 spam\tFree entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\n",
      "3 ham\tU dun say so early hor... U c already then say...\n",
      "4 ham\tNah I don't think he goes to usf, he lives around here though\n",
      "5 spam\tFreeMsg Hey there darling it's been 3 week's now and no word back! I'd like some fun you up for it still? Tb ok! XxX std chgs to send, آ£1.50 to rcv\n",
      "6 ham\tEven my brother is not like to speak with me. They treat me like aids patent.\n",
      "7 ham\tAs per your request 'Melle Melle (Oru Minnaminunginte Nurungu Vettam)' has been set as your callertune for all Callers. Press *9 to copy your friends Callertune\n",
      "8 spam\tWINNER!! As a valued network customer you have been selected to receivea آ£900 prize reward! To claim call 09061701461. Claim code KL341. Valid 12 hours only.\n",
      "9 spam\tHad your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free! Call The Mobile Update Co FREE on 08002986030\n"
     ]
    }
   ],
   "source": [
    "# Import messages from file\n",
    "messages = [line.rstrip() for line in open('smsspamcollection/SMSSpamCollection')]\n",
    "\n",
    "# Show the first 10 messages\n",
    "for num, message in enumerate(messages[:10]):\n",
    "    print(num, message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see in the print above, this is a TSV (_Tab Separated Values_) file and secondly messages have labels _ham_ and _spam_, which corresponds to _normal_ and _spam_ messages, respectively.\n",
    "\n",
    "In the continue the main goal of this article is to setup a machine learning model to identify _ham_ and _spam_ messages itself. It would be a supervised method and we will use some part of the messages for the training process. \n",
    "\n",
    "But before that, we will do some analysis on the messages. For convenience "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas library\n",
    "import pandas as pd \n",
    "\n",
    "df_messages = pd.read_csv('smsspamcollection/SMSSpamCollection',\n",
    "                        sep='\\t', names=['label','message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                            message\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham               Will ü b going to esplanade fr home?\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the dataframe\n",
    "df_messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, there are 5572 messages in our dataframe. First of all we extract some general information from the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5572</td>\n",
       "      <td>5572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>5169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>ham</td>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>4825</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                 message\n",
       "count   5572                    5572\n",
       "unique     2                    5169\n",
       "top      ham  Sorry, I'll call later\n",
       "freq    4825                      30"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Some general info of the messages dataframe\n",
    "df_messages.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the description, there are 2 unique labels, ham and spam. Ham is the more frequent label which repeated 4825 times. Almost, all of the messages were different and the top repeated message were _\"Sorry, I'll call later\"_, which repeated 30 times. \n",
    "\n",
    "We can extract info of each label separately to have more detailed informaiton:     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">message</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ham</th>\n",
       "      <td>4825</td>\n",
       "      <td>4516</td>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>747</td>\n",
       "      <td>653</td>\n",
       "      <td>Please call our customer service representativ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      message                                                               \n",
       "        count unique                                                top freq\n",
       "label                                                                       \n",
       "ham      4825   4516                             Sorry, I'll call later   30\n",
       "spam      747    653  Please call our customer service representativ...    4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_messages.groupby('label').describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So here we can find out more details on each of the labels. In the next step we'll extract some features of the messages, like length etc, and add them to the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                            message  length\n",
       "0      ham  Go until jurong point, crazy.. Available only ...     111\n",
       "1      ham                      Ok lar... Joking wif u oni...      29\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...     155\n",
       "3      ham  U dun say so early hor... U c already then say...      49\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...      61\n",
       "...    ...                                                ...     ...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...     160\n",
       "5568   ham               Will ü b going to esplanade fr home?      36\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...      57\n",
       "5570   ham  The guy did some bitching but I acted like i'd...     125\n",
       "5571   ham                         Rofl. Its true to its name      26\n",
       "\n",
       "[5572 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract and add length of each message to the dataframe\n",
    "df_messages['length'] = df_messages['message'].apply(len)\n",
    "\n",
    "# Check the dataframe\n",
    "df_messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization\n",
    "\n",
    "It would be nice of we add some visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='length', ylabel='Count'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot histogram of the length of messages\n",
    "# + also for labels separately\n",
    "\n",
    "fig, axes = plt.subplots(1,2, figsize=(15,5))\n",
    "sns.histplot(df_messages, x='length', bins = 50, ax=axes[0])\n",
    "sns.histplot(df_messages, x='length', hue='label', bins = 50, ax=axes[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Pre-Processing\n",
    "\n",
    "Here the messages are in the string format. The issue is that we need a solution to convert these data to some numerical features as it is required for classifications models. There are several methods to convert the corpus to the numerical features vectors, the simples one is \"Bag of words\". In this model every word consider as a single quantity and the whole corpus considered as a bag of single words.\n",
    "\n",
    "The bag-of-words model is commonly used in methods of document classification where the (frequency of) occurrence of each word is used as a feature for training a classifier.\n",
    "\n",
    "So the porpuse of this section is to convert raw messages (sequence of characters) into vectors (sequences of numbers).\n",
    "\n",
    "In the continue, first, we would split messages into list of individual words. We like to remove punctuations and also common words ([stop words](https://en.wikipedia.org/wiki/Stop_word) in computing), such as 'the', 'a', etc. For this porpuse, we would benefited by the built-in functions in NLTK and string libraries. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before seting up a funciton, it would be useful to check the process on a temporary test text and see what would happen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is just a text including some common words like the a  and bunch of punctuations OK'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import string library to analyze the text\n",
    "import string\n",
    "\n",
    "# test text\n",
    "test = 'This is just a text, including some common words, like: the, a, ... and bunch of punctuations! OK?'\n",
    "\n",
    "# remove punctuations, join the letters and then check it\n",
    "test_nopunc = [char for char in test if char not in string.punctuation]\n",
    "test_nopunc = ''.join(test_nopunc)\n",
    "test_nopunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"i, me, my, myself, we, our, ours, ourselves, you, you're, you've, you'll, you'd, your, yours, yourself, yourselves, he, him, his\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import library to remove stop words\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Show some stop words\n",
    "', '.join(stopwords.words('english')[0:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we would apply removing stop words on splitted test_nopunc. We use .lower() method to make sure that there aren't any capital letters in our list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['text', 'including', 'common', 'words', 'like', 'bunch', 'punctuations', 'OK']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove stop words and show the result\n",
    "test_nopunc_cleaned = [word for word in test_nopunc.split() if word.lower() not in stopwords.words('english')]\n",
    "test_nopunc_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we know that everything wokrs fine, we can put all of them together in a function to apply on our textdata and clean them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    '''\n",
    "    Function to clean the text:\n",
    "    - remove punctuations\n",
    "    - remove stop words\n",
    "    \n",
    "    Args:\n",
    "        text         (str): A text which is supposed to be pre-processed\n",
    "        \n",
    "    Returns:\n",
    "        text_cleaned (lst): list of strings (single words)\n",
    "    '''\n",
    "    \n",
    "    # remove punctuations\n",
    "    nopunc = [char for char in text if char not in string.punctuation]\n",
    "\n",
    "    # Join the characters again to form the string.\n",
    "    nopunc = ''.join(nopunc)\n",
    "    \n",
    "    # remove stopwords\n",
    "    text_cleaned = [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]\n",
    "    \n",
    "    return text_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "review of the original dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                            message  length\n",
       "0      ham  Go until jurong point, crazy.. Available only ...     111\n",
       "1      ham                      Ok lar... Joking wif u oni...      29\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...     155\n",
       "3      ham  U dun say so early hor... U c already then say...      49\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...      61\n",
       "...    ...                                                ...     ...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...     160\n",
       "5568   ham               Will ü b going to esplanade fr home?      36\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...      57\n",
       "5570   ham  The guy did some bitching but I acted like i'd...     125\n",
       "5571   ham                         Rofl. Its true to its name      26\n",
       "\n",
       "[5572 rows x 3 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# review of the messages dataframe\n",
    "df_messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the continue we wil __tokenize__ the messages, and convert the text strings into a list of __tokens__ (the important word that we need). To save time lets check the first 10 messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [Go, jurong, point, crazy, Available, bugis, n...\n",
       "1                       [Ok, lar, Joking, wif, u, oni]\n",
       "2    [Free, entry, 2, wkly, comp, win, FA, Cup, fin...\n",
       "3        [U, dun, say, early, hor, U, c, already, say]\n",
       "4    [Nah, dont, think, goes, usf, lives, around, t...\n",
       "5    [FreeMsg, Hey, darling, 3, weeks, word, back, ...\n",
       "6    [Even, brother, like, speak, treat, like, aids...\n",
       "7    [per, request, Melle, Melle, Oru, Minnaminungi...\n",
       "8    [WINNER, valued, network, customer, selected, ...\n",
       "9    [mobile, 11, months, U, R, entitled, Update, l...\n",
       "Name: message, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_messages['message'][0:10].apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorizaiton\n",
    "\n",
    "In this section we will convert messages, which I have them now as list of tokens (also known as [lemmas](https://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html)) into vectors that be suitable for machine learning models. \n",
    "\n",
    "For this purpose, we'll do it in the following steps:\n",
    "\n",
    "1. __Term frequency:__ count the number of time a word occurs in a message\n",
    "2. __Inverse document frequency:__ Weigh the counts (high frequent tokens get lower weights)\n",
    "3. __L2 norm:__ Normalize the vectors to unit length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Built in __CountVectorizer__ in SciKit Learn do the first step (term frequency). This model will convert a collection of text documents to a matrix of token counts. \n",
    "The output would be a [sparse matrix](https://en.wikipedia.org/wiki/Sparse_matrix) as there are lots of words in all messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11425\n"
     ]
    }
   ],
   "source": [
    "# Import CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# make bag of words (bow) applying CountVectorizer\n",
    "# specify the analyzer to be our own previously defined function\n",
    "bow = CountVectorizer(analyzer=clean_text).fit(df_messages['message'])\n",
    "\n",
    "# print total number of words\n",
    "print(len(bow.vocabulary_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there are 11425 unique words after removing punctuations and stop words! \n",
    "\n",
    "Lets check one of the messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Even my brother is not like to speak with me. They treat me like aids patent.'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select and check a sample message\n",
    "message_sample = df_messages['message'][6]\n",
    "message_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1802)\t1\n",
      "  (0, 4590)\t1\n",
      "  (0, 5193)\t1\n",
      "  (0, 7800)\t2\n",
      "  (0, 8761)\t1\n",
      "  (0, 9971)\t1\n",
      "  (0, 10629)\t1\n",
      "(1, 11425)\n"
     ]
    }
   ],
   "source": [
    "# Make bag of words of the sample message and print counts\n",
    "bow_sample = bow.transform([message_sample])\n",
    "print(bow_sample)\n",
    "print(bow_sample.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are seven unique words in the sixth message, only one of them appears twice. Let's see what was that word:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'like'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Name of the repeated word (row 7800)\n",
    "bow.get_feature_names()[7800]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! And we can do the same with the entire of SMS corpus using _.transform_ method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Sparse Matrix: (5572, 11425)\n",
      "Number of non-zero occurences: 50548\n",
      "Sparsity: 0.08%\n"
     ]
    }
   ],
   "source": [
    "# apply transformation on the whole message dataframe\n",
    "message_bow = bow.transform(df_messages['message'])\n",
    "\n",
    "# print some properties\n",
    "print('Shape of Sparse Matrix: {}'.format(message_bow.shape))\n",
    "print('Number of non-zero occurences: {}'.format(message_bow.nnz))\n",
    "print('Sparsity: {:.2f}%'.format(100*message_bow.nnz/(message_bow.shape[0]*message_bow.shape[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
